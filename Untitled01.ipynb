{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "nWtz8_LRfZtd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qbeNHiUseo8c"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "HMEA_UjtkdDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = pd.read_csv('/content/mushrooms.csv')\n",
        "df = df_original.copy()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "yy9snJiGexo_",
        "outputId": "e9337fad-420c-4ae6-d0aa-c1b2d25d723f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
              "0        p         x           s         n       t    p               f   \n",
              "1        e         x           s         y       t    a               f   \n",
              "2        e         b           s         w       t    l               f   \n",
              "3        p         x           y         w       t    p               f   \n",
              "4        e         x           s         g       f    n               f   \n",
              "...    ...       ...         ...       ...     ...  ...             ...   \n",
              "8119     e         k           s         n       f    n               a   \n",
              "8120     e         x           s         n       f    n               a   \n",
              "8121     e         f           s         n       f    n               a   \n",
              "8122     p         k           y         n       f    y               f   \n",
              "8123     e         x           s         n       f    n               a   \n",
              "\n",
              "     gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
              "0               c         n          k  ...                        s   \n",
              "1               c         b          k  ...                        s   \n",
              "2               c         b          n  ...                        s   \n",
              "3               c         n          n  ...                        s   \n",
              "4               w         b          k  ...                        s   \n",
              "...           ...       ...        ...  ...                      ...   \n",
              "8119            c         b          y  ...                        s   \n",
              "8120            c         b          y  ...                        s   \n",
              "8121            c         b          n  ...                        s   \n",
              "8122            c         n          b  ...                        k   \n",
              "8123            c         b          y  ...                        s   \n",
              "\n",
              "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
              "0                         w                      w         p          w   \n",
              "1                         w                      w         p          w   \n",
              "2                         w                      w         p          w   \n",
              "3                         w                      w         p          w   \n",
              "4                         w                      w         p          w   \n",
              "...                     ...                    ...       ...        ...   \n",
              "8119                      o                      o         p          o   \n",
              "8120                      o                      o         p          n   \n",
              "8121                      o                      o         p          o   \n",
              "8122                      w                      w         p          w   \n",
              "8123                      o                      o         p          o   \n",
              "\n",
              "     ring-number ring-type spore-print-color population habitat  \n",
              "0              o         p                 k          s       u  \n",
              "1              o         p                 n          n       g  \n",
              "2              o         p                 n          n       m  \n",
              "3              o         p                 k          s       u  \n",
              "4              o         e                 n          a       g  \n",
              "...          ...       ...               ...        ...     ...  \n",
              "8119           o         p                 b          c       l  \n",
              "8120           o         p                 b          v       l  \n",
              "8121           o         p                 b          c       l  \n",
              "8122           o         e                 w          v       l  \n",
              "8123           o         p                 o          c       l  \n",
              "\n",
              "[8124 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2711466-84b0-4acf-b159-50bddf4e566a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e</td>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8119</th>\n",
              "      <td>e</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8120</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>v</td>\n",
              "      <td>l</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8121</th>\n",
              "      <td>e</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8122</th>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>b</td>\n",
              "      <td>...</td>\n",
              "      <td>k</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>l</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8123</th>\n",
              "      <td>e</td>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>...</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8124 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2711466-84b0-4acf-b159-50bddf4e566a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2711466-84b0-4acf-b159-50bddf4e566a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2711466-84b0-4acf-b159-50bddf4e566a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# No missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQPiBErwe4L6",
        "outputId": "2f45c58c-a3bb-4468-f523-70c5b9bb4750"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class                       0\n",
              "cap-shape                   0\n",
              "cap-surface                 0\n",
              "cap-color                   0\n",
              "bruises                     0\n",
              "odor                        0\n",
              "gill-attachment             0\n",
              "gill-spacing                0\n",
              "gill-size                   0\n",
              "gill-color                  0\n",
              "stalk-shape                 0\n",
              "stalk-root                  0\n",
              "stalk-surface-above-ring    0\n",
              "stalk-surface-below-ring    0\n",
              "stalk-color-above-ring      0\n",
              "stalk-color-below-ring      0\n",
              "veil-type                   0\n",
              "veil-color                  0\n",
              "ring-number                 0\n",
              "ring-type                   0\n",
              "spore-print-color           0\n",
              "population                  0\n",
              "habitat                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide dataset into X & Y to use different encoding techniques\n",
        "Y = df['class']\n",
        "X = df.drop(columns=['class'])\n",
        "print('X.shape =',X.shape)\n",
        "print('X.shape =',Y.shape)"
      ],
      "metadata": {
        "id": "zKxwayTyff8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eca695d-3810-4fd4-c797-4cabe9f0879e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (8124, 22)\n",
            "X.shape = (8124,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting the categ columns\n",
        "categ_columns = X.select_dtypes(include=['object']).columns\n",
        "categ_var = X[categ_columns]\n",
        "\n",
        "#ont hot encoding\n",
        "enc = OneHotEncoder(handle_unknown='ignore').fit(categ_var)\n",
        "transformed = enc.fit_transform(X[categ_columns]).toarray()\n",
        "onehot_df = pd.DataFrame(transformed, columns=enc.get_feature_names())\n",
        "X = pd.concat([X, onehot_df], axis=1)\n",
        "X = X.drop(columns=categ_columns)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tmNm9ongMfh",
        "outputId": "ee855c50-198e-4582-8ce6-2abc85b29083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      x0_b  x0_c  x0_f  x0_k  x0_s  x0_x  x1_f  x1_g  x1_s  x1_y  ...  x20_s  \\\n",
            "0      0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...    1.0   \n",
            "1      0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "2      1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "3      0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0  ...    1.0   \n",
            "4      0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
            "8119   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "8120   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "8121   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "8122   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0  ...    0.0   \n",
            "8123   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0  ...    0.0   \n",
            "\n",
            "      x20_v  x20_y  x21_d  x21_g  x21_l  x21_m  x21_p  x21_u  x21_w  \n",
            "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
            "1       0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
            "2       0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  \n",
            "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
            "4       0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
            "...     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
            "8119    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "8120    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "8121    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "8122    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "8123    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
            "\n",
            "[8124 rows x 117 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "print(Y)\n",
        "print('Y.shape =', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIiQJLUdiCAJ",
        "outputId": "15e2ecd3-0520-43fd-81c7-4b783fdd2351"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 ... 0 1 0]\n",
            "Y.shape = (8124,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 100, stratify = Y)"
      ],
      "metadata": {
        "id": "v2_KSje7ihj7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_dev, X_test, Y_dev, Y_test = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 100, stratify = Y_test)"
      ],
      "metadata": {
        "id": "RYzq9Pg8je2V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [X_train, Y_train, X_test, Y_test, X_dev, Y_dev]\n",
        "for i in range(len(data)):\n",
        "  if i %2 != 0: \n",
        "    data[i] = np.reshape(data[i],(1,data[i].shape[0]))\n",
        "  else:\n",
        "    data[i] = data[i].T\n",
        "  print(data[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-IGKc9Ih0NJ",
        "outputId": "f73acf35-0bb3-4890-8580-0e32c9e5b74d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117, 6499)\n",
            "(1, 6499)\n",
            "(117, 407)\n",
            "(1, 407)\n",
            "(117, 406)\n",
            "(1, 406)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Network"
      ],
      "metadata": {
        "id": "mU3X52uAkcGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ],
      "metadata": {
        "id": "jVp0p5qCqvQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialization(dim_array):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    dim_array -- python array (list) containing the dimensions of each layer in our network and dimension of input layer 1st\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    L = len(dim_array)            # number of layers in Network\n",
        "    np.random.seed(3)\n",
        "    parameters = {}               # Ws and bs \n",
        "\n",
        "    for i in range(1,L):\n",
        "      parameters[\"W\" + str(i)] = np.random.randn(dim_array[i], dim_array[i-1])*np.sqrt(2/dim_array[i-1])  # used Xavier Initialization to prevent exploding and vanishing vectors\n",
        "      parameters[\"b\" + str(i)] = np.zeros((dim_array[i],1))                                               # used normal distribution for random selection, reduce chance of extreme values to be selected, better for G.D\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "3QiFYP0NqyyW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = initialization([117,8,4,3,1])"
      ],
      "metadata": {
        "id": "LRve0iCe1lVq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Propagation"
      ],
      "metadata": {
        "id": "Slgupo5bqzn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper Functions\n",
        "\n",
        "def sigmoid(Z):\n",
        "\n",
        "  \"\"\"\n",
        "    Arguments:\n",
        "    Z -- numpy array\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of sigmoid function\n",
        "    cache -- contains argument Z\n",
        "  \"\"\"\n",
        "\n",
        "  A = 1 / (1 + np.exp(-Z))\n",
        "  cache = Z\n",
        "  return A, cache\n",
        "\n",
        "def relu(Z):\n",
        "\n",
        "  \"\"\"\n",
        "    Arguments:\n",
        "    Z -- numpy array\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of RELU function\n",
        "    cache -- contains argument Z\n",
        "  \"\"\"\n",
        "  A = np.maximum(0,Z)\n",
        "  cache = Z\n",
        "  return A, cache"
      ],
      "metadata": {
        "id": "qvMadue2prEb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(W,A,b):\n",
        "  \"\"\"\n",
        "    Arguments:\n",
        "    W -- numpy array representing weight\n",
        "    A -- input of RELU function\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of sigmoid function\n",
        "    cache -- contains argument Z\n",
        "  \"\"\"\n",
        "  Z = np.dot(W,A) + b\n",
        "  cache = (A, W, b)\n",
        "  return Z, cache"
      ],
      "metadata": {
        "id": "2Q0-1alvkAr-"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_activation(A_prev,W,b,activation):\n",
        "  \n",
        "  if activation == 'sigmoid':\n",
        "    Z, linear_cache = linear_forward(W,A_prev,b)\n",
        "    A, activation_cache = sigmoid(Z)\n",
        "\n",
        "  elif activation == 'relu':\n",
        "    Z, linear_cache = linear_forward(W,A_prev,b)\n",
        "    A, activation_cache = relu(Z)\n",
        "  cache = (linear_cache, activation_cache)\n",
        "  return A,cache"
      ],
      "metadata": {
        "id": "xJulFIpApTZ0"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X,parameters):\n",
        "  L = len(parameters.keys())//2  \n",
        "  A = X\n",
        "  caches = []\n",
        "  # LINEAR -- RELU 3 TIMES\n",
        "  for i in range(1,L):\n",
        "    A_prev = A\n",
        "    A, relu_cache = choose_activation(                      A_prev,parameters[\"W\" + str(i)],\n",
        "                      parameters[\"b\" + str(i)],\n",
        "                      activation='relu')\n",
        "    caches.append(relu_cache)\n",
        "\n",
        "  # LINEAR -- SIGMOID 1 TIME\n",
        "  #print(pd.Series(A[0]).describe())\n",
        "  AL, sigmoid_cache = choose_activation(                        A_prev,parameters[\"W\" + str(i)],\n",
        "                        parameters[\"b\" + str(i)],\n",
        "                        activation='sigmoid')\n",
        "  caches.append(sigmoid_cache)\n",
        "  return AL, caches"
      ],
      "metadata": {
        "id": "xA8frCgoqceB"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AL, caches = forward_propagation(X_train.T,parameters)"
      ],
      "metadata": {
        "id": "nSb2LAidypuG"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(AL[0]).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o08uprTGJN84",
        "outputId": "2db339a0-5d04-4089-9ffa-45f7ee998f8f"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    6499.000000\n",
              "mean        0.607726\n",
              "std         0.065018\n",
              "min         0.397974\n",
              "25%         0.560229\n",
              "50%         0.612193\n",
              "75%         0.656759\n",
              "max         0.750516\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost"
      ],
      "metadata": {
        "id": "b6P20GjdJ_5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(AL,y):\n",
        "\n",
        "  m = y.shape[1]\n",
        "  cost = -1/m*(np.sum(y*np.log(AL)+(1-y)*np.log(1-AL)))\n",
        "  cost = np.squeeze(cost) \n",
        "  return cost"
      ],
      "metadata": {
        "id": "qTFLsLAGKBLY"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_reshaped = np.reshape(Y_train,(1,6499))\n",
        "cost_function(AL,Y_train_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWk4N3euMEVI",
        "outputId": "de5c7679-a4bc-4e56-d814-056b3aed960f"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6743943096030101"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BACKPRPO\n"
      ],
      "metadata": {
        "id": "t3fXtrIdMVlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dAL = - (np.divide(Y_train_reshaped, AL) - np.divide(1 - Y_train_reshaped, 1 - AL))\n"
      ],
      "metadata": {
        "id": "JpdeZqCDP0eY"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single RELU unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
        "    \n",
        "    # When z <= 0, you should set dz to 0 as well. \n",
        "    dZ[Z <= 0] = 0\n",
        "    \n",
        "    \n",
        "    return dZ\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single SIGMOID unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    \n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQS0kqWtQ16A"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "    Arguments:\n",
        "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = np.dot(dZ,A_prev.T)/m  \n",
        "    db = np.sum(dZ,axis=1,keepdims=True)/m\n",
        "    dA_prev = np.dot(W.T,dZ)\n",
        "\n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "MXszp8qhMi5v"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
        "    \n",
        "    Arguments:\n",
        "    dA -- post-activation gradient for current layer l \n",
        "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "    \n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"relu\":\n",
        "        #(≈ 2 lines of code)\n",
        "        dZ =relu_backward(dA, activation_cache) \n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "        \n",
        "    elif activation == \"sigmoid\":\n",
        "        #(≈ 2 lines of code)\n",
        "        dZ =sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "        # YOUR CODE STARTS HERE\n",
        " \n",
        "        # YOUR CODE ENDS HERE\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "wpJld9IkQQDi"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "    \n",
        "    Arguments:\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
        "    \n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ... \n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ... \n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    #(1 line of code)\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    # YOUR CODE STARTS HERE\n",
        "    \n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    #(approx. 5 lines)\n",
        "    current_cache = caches[L-1]\n",
        "    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, activation='sigmoid')\n",
        "    grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(L)] = dW_temp\n",
        "    grads[\"db\" + str(L)] = db_temp\n",
        "    # YOUR CODE STARTS HERE\n",
        "    \n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    # Loop from l=L-2 to l=0\n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
        "        #(approx. 5 lines)\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation='relu')\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "yNh9htqbQW71"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_model_backward(AL, Y_train_reshaped, caches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGm_VYuGRIzm",
        "outputId": "daeb271e-3bee-4c05-d0b4-e85f3a4cd3de"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dA0': array([[ 0.00029721,  0.23629374,  0.00926245, ...,  0.02566916,\n",
              "          0.04186596, -0.00328531],\n",
              "        [-0.01487763,  0.10760315,  0.04185676, ..., -0.00515917,\n",
              "          0.02473801, -0.0050098 ],\n",
              "        [-0.01184904, -0.01157508,  0.07654934, ...,  0.00308024,\n",
              "          0.00348551, -0.003378  ],\n",
              "        ...,\n",
              "        [ 0.00025949,  0.0262632 ,  0.01271389, ..., -0.01032451,\n",
              "          0.04053509, -0.00769537],\n",
              "        [ 0.02903733, -0.154051  , -0.12261473, ...,  0.03085059,\n",
              "         -0.08940307,  0.02499793],\n",
              "        [-0.01001253, -0.07163556,  0.04959827, ..., -0.00592737,\n",
              "         -0.023725  ,  0.00697942]]),\n",
              " 'dA1': array([[ 0.09926384,  0.19612545, -0.39896974, ...,  0.0685301 ,\n",
              "         -0.19279561,  0.04243101],\n",
              "        [-0.04092394, -0.26831227,  0.16448501, ...,  0.01170603,\n",
              "         -0.03293255, -0.00555087],\n",
              "        [-0.05577438,  0.90358089,  0.22417317, ..., -0.11030084,\n",
              "          0.31030916, -0.05703423],\n",
              "        ...,\n",
              "        [-0.08533081,  0.43118195,  0.34296888, ..., -0.19506182,\n",
              "          0.54876708, -0.08219202],\n",
              "        [ 0.0063385 , -0.13693667, -0.02547625, ...,  0.05578015,\n",
              "         -0.1569262 ,  0.0151734 ],\n",
              "        [-0.10590372,  0.43904472,  0.42565731, ..., -0.08315283,\n",
              "          0.23393372, -0.05325415]]),\n",
              " 'dA2': array([[ 0.12049246, -0.52989126, -0.48429362, ...,  0.19978971,\n",
              "         -0.56206803,  0.09462518],\n",
              "        [ 0.02801457, -0.12320006, -0.11259858, ...,  0.04645123,\n",
              "         -0.13068118,  0.02200041],\n",
              "        [-0.13856547,  0.60937116,  0.55693421, ..., -0.22975673,\n",
              "          0.64637422, -0.10881828],\n",
              "        [ 0.05442636, -0.23935149, -0.21875507, ...,  0.09024486,\n",
              "         -0.25388571,  0.04274212]]),\n",
              " 'dA3': array([[-0.04947571,  0.21757998,  0.19885702, ..., -0.08203615,\n",
              "          0.23079216, -0.03885428],\n",
              "        [-0.00314152,  0.01381552,  0.01262668, ..., -0.00520899,\n",
              "          0.01465445, -0.0024671 ],\n",
              "        [-0.13347462,  0.58698308,  0.53647264, ..., -0.22131555,\n",
              "          0.62262666, -0.10482034]]),\n",
              " 'dW1': array([[-2.55416979e-05,  0.00000000e+00, -1.52283393e-05,\n",
              "          0.00000000e+00,  0.00000000e+00, -7.66657514e-06,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.55416979e-05,\n",
              "         -2.28949144e-05,  0.00000000e+00, -7.71175059e-06,\n",
              "         -1.51831638e-05,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.55416979e-05,  0.00000000e+00, -2.28949144e-05,\n",
              "         -2.55416979e-05,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.28949144e-05,\n",
              "         -2.55416979e-05,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.28949144e-05, -2.55416979e-05,\n",
              "         -4.84366123e-05,  0.00000000e+00, -4.84366123e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -4.84366123e-05,\n",
              "          0.00000000e+00, -4.84366123e-05,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.55416979e-05, -2.28949144e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.28949144e-05, -2.55416979e-05,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.55416979e-05,\n",
              "         -2.28949144e-05,  0.00000000e+00, -2.28949144e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.55416979e-05,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.28949144e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.55416979e-05,\n",
              "          0.00000000e+00, -4.84366123e-05,  0.00000000e+00,\n",
              "          0.00000000e+00, -4.84366123e-05,  0.00000000e+00,\n",
              "         -2.28949144e-05,  0.00000000e+00, -2.55416979e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.28949144e-05, -2.55416979e-05,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.55416979e-05,  0.00000000e+00,\n",
              "         -2.28949144e-05,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.28949144e-05,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.55416979e-05,  0.00000000e+00, -2.28949144e-05,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.55416979e-05,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "        [ 2.36959601e-03, -1.21902043e-05, -1.15866524e-02,\n",
              "         -7.10231792e-03,  1.31629079e-04, -1.19682741e-02,\n",
              "          3.02949350e-05, -1.16535005e-04, -1.24050627e-02,\n",
              "         -1.56769068e-02, -8.28311714e-04,  9.03430509e-05,\n",
              "         -1.01526949e-02, -3.15717191e-03, -1.34254288e-02,\n",
              "         -3.34972020e-04,  8.90564654e-06,  6.33917408e-05,\n",
              "         -1.01322949e-03,  5.80958856e-04, -2.72536800e-02,\n",
              "         -9.14529572e-04,  1.82945659e-03, -6.58015974e-04,\n",
              "         -1.25780573e-02,  4.31557781e-03, -1.49306406e-04,\n",
              "          3.58493783e-03, -3.62260350e-03, -1.05932568e-02,\n",
              "         -1.02969418e-02, -7.08157146e-05, -2.80973938e-02,\n",
              "         -3.19813848e-02,  3.81317522e-03,  6.71013884e-04,\n",
              "         -2.88392234e-02, -2.48385953e-02,  0.00000000e+00,\n",
              "         -3.89958053e-04, -2.37858428e-03,  6.45047902e-04,\n",
              "          1.21696110e-03, -2.47433757e-06, -2.24524909e-03,\n",
              "         -8.26295039e-05, -3.64467416e-04,  3.20904181e-04,\n",
              "         -4.91648038e-05, -4.00750375e-03, -2.41607058e-02,\n",
              "         -2.47791730e-02, -8.14044591e-03,  3.78086042e-03,\n",
              "         -4.19936052e-04,  1.39048496e-03,  4.77797628e-04,\n",
              "         -2.11766057e-02, -7.50025857e-03,  3.08571139e-05,\n",
              "         -8.39445693e-04, -2.16951910e-02, -6.24202913e-03,\n",
              "          6.08456298e-04, -1.10144148e-03, -1.49306406e-04,\n",
              "          5.43124889e-06, -2.31378897e-04, -1.01873442e-03,\n",
              "         -1.32914352e-05, -1.38301482e-02, -1.17430550e-02,\n",
              "         -8.62849591e-05, -8.51661691e-04, -1.49306406e-04,\n",
              "          6.12460247e-06, -2.20253550e-04, -1.10086484e-03,\n",
              "         -1.32914352e-05, -1.65854452e-02, -8.75340183e-03,\n",
              "         -5.00109190e-04, -2.81682096e-02,  1.40794169e-06,\n",
              "         -1.46993769e-05, -2.80686332e-02, -8.62849591e-05,\n",
              "         -1.49306406e-04, -2.85545300e-02,  5.35626847e-04,\n",
              "         -2.24265579e-02,  1.01813068e-04, -5.04874368e-03,\n",
              "         -1.49306406e-04, -6.45414657e-04,  1.00617199e-05,\n",
              "         -8.52784758e-03,  3.25370121e-03,  1.83947574e-03,\n",
              "         -3.10285396e-05, -3.70726592e-04,  5.35013989e-04,\n",
              "         -2.48812483e-02,  4.38882887e-06,  8.18530315e-04,\n",
              "         -4.39298501e-04,  2.67901790e-03,  1.58543688e-04,\n",
              "         -3.03462699e-02, -1.03873304e-03, -7.82353915e-03,\n",
              "          1.16438776e-03, -8.04972163e-03,  2.03385099e-03,\n",
              "         -1.20912530e-02, -3.42742471e-03,  2.54902251e-05],\n",
              "        [-1.78581984e-04,  0.00000000e+00,  4.05256649e-02,\n",
              "          3.98713367e-02, -7.59169070e-04,  2.66204626e-02,\n",
              "         -4.89628593e-03,  5.72078383e-05,  5.45550255e-02,\n",
              "          5.63637657e-02,  2.96636005e-03, -6.43447510e-05,\n",
              "          4.43334872e-02,  1.01346127e-02,  4.34162315e-02,\n",
              "         -7.39914227e-05, -2.26715039e-04,  0.00000000e+00,\n",
              "          2.80957617e-03,  2.78449679e-03,  1.17952602e-01,\n",
              "         -1.18728888e-02, -4.21403321e-04,  2.51473511e-04,\n",
              "          5.72494818e-02, -1.12739331e-03,  2.18250419e-04,\n",
              "         -2.54667450e-02,  6.71372250e-04,  4.10138486e-02,\n",
              "          3.36908282e-02, -1.89422770e-03,  1.07973941e-01,\n",
              "          1.08540585e-01, -2.46087157e-03,  2.44564310e-03,\n",
              "          1.03634070e-01,  1.05275218e-01, -4.45706339e-04,\n",
              "          4.15083010e-03,  1.01905440e-02, -2.30320407e-04,\n",
              "         -5.33531665e-03, -8.49086850e-04,  3.91134639e-03,\n",
              "          0.00000000e+00, -6.42653259e-03, -3.60718865e-03,\n",
              "         -5.54073606e-04,  1.33079406e-02,  9.27717725e-02,\n",
              "          1.03110521e-01,  4.00351515e-03,  2.18250419e-04,\n",
              "         -1.17884896e-03, -7.37242726e-05,  5.81092362e-03,\n",
              "          6.95829902e-02,  3.07637742e-02, -7.79749468e-05,\n",
              "          4.44500483e-03,  6.78213166e-02,  3.28778987e-02,\n",
              "          9.35493060e-04,  8.85743400e-03,  2.18250419e-04,\n",
              "         -2.24205690e-04, -4.99685677e-03,  3.13457813e-03,\n",
              "         -2.11247812e-03,  5.28272296e-02,  4.83757615e-02,\n",
              "          0.00000000e+00,  4.52412803e-03,  2.18250419e-04,\n",
              "         -4.45706339e-04, -5.89271843e-03,  5.89653170e-03,\n",
              "         -2.11247812e-03,  5.37667970e-02,  4.98177714e-02,\n",
              "          3.07137431e-04,  1.06079713e-01, -1.24298858e-03,\n",
              "         -8.69489542e-04,  1.08192191e-01,  0.00000000e+00,\n",
              "          2.18250419e-04,  1.06666118e-01, -8.04655210e-04,\n",
              "          1.04812175e-01, -2.67575965e-04,  1.62466232e-02,\n",
              "          2.18250419e-04, -1.49297592e-02, -5.80179308e-04,\n",
              "          2.64113649e-02, -1.24099801e-02, -1.09576616e-02,\n",
              "         -4.22777900e-04,  7.25027029e-05, -6.40116955e-04,\n",
              "          1.05150684e-01, -5.44122385e-04, -4.94502453e-04,\n",
              "         -1.19710166e-03, -2.07878426e-04,  4.56461541e-03,\n",
              "          1.05215935e-01, -1.80135480e-03,  2.47391902e-02,\n",
              "          5.41212902e-03,  2.72996672e-02,  0.00000000e+00,\n",
              "          4.40596197e-02,  5.01481336e-03, -4.45706339e-04],\n",
              "        [ 1.05191398e-03,  0.00000000e+00, -8.43724796e-03,\n",
              "         -3.41433766e-03,  6.82060029e-05, -1.30872215e-03,\n",
              "          1.97643252e-04,  0.00000000e+00, -8.61884312e-03,\n",
              "         -3.61898792e-03, -9.91679465e-04,  0.00000000e+00,\n",
              "         -3.79762790e-03, -1.36031216e-03, -3.41007678e-03,\n",
              "         -8.54780486e-05,  6.49555156e-05,  1.31769026e-04,\n",
              "         -1.23126962e-03, -1.36046835e-03, -1.70203840e-02,\n",
              "          4.98019619e-03,  7.71135904e-04, -7.65861227e-04,\n",
              "         -1.20707818e-02,  1.98910631e-03,  0.00000000e+00,\n",
              "          7.92570588e-03, -1.85772051e-03, -2.09440082e-03,\n",
              "         -5.93737148e-03,  2.32640019e-04, -1.22728278e-02,\n",
              "         -1.26528608e-02,  6.12672993e-04,  1.17488715e-03,\n",
              "         -1.32150749e-02, -1.14604585e-02,  6.25216021e-04,\n",
              "         -8.19683898e-04, -2.21133418e-03, -7.38246046e-05,\n",
              "          1.41318160e-03,  1.44432617e-04, -3.28342300e-03,\n",
              "         -9.37879789e-05,  1.68947974e-03,  2.00794896e-03,\n",
              "          2.20653852e-05, -4.15792809e-03, -7.88225969e-03,\n",
              "         -9.48333208e-03, -3.48263618e-03,  9.78478018e-04,\n",
              "         -1.28742823e-03,  1.23473068e-03, -1.46881915e-03,\n",
              "         -1.16173129e-02,  9.87061780e-04,  5.88824531e-05,\n",
              "         -6.95599251e-04, -1.07068601e-02, -1.82609705e-03,\n",
              "          1.18836858e-03, -2.59241886e-03,  0.00000000e+00,\n",
              "          1.02071178e-03,  1.97880065e-03, -1.58069544e-03,\n",
              "          2.32640019e-04, -8.59877517e-03, -2.50045076e-03,\n",
              "          0.00000000e+00, -7.76018750e-04,  0.00000000e+00,\n",
              "          5.37227909e-04,  1.62262961e-03, -3.09091734e-03,\n",
              "          2.32640019e-04, -4.94433186e-03, -5.62141737e-03,\n",
              "          0.00000000e+00, -1.20401878e-02,  1.11210111e-04,\n",
              "          1.21429908e-04, -1.22728278e-02,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.36157293e-02,  1.57554155e-03,\n",
              "         -9.66060613e-03,  2.39283836e-04, -5.87766836e-03,\n",
              "          0.00000000e+00,  3.25880286e-03,  1.96679205e-05,\n",
              "         -8.40281185e-03,  2.37047507e-03,  3.63786032e-03,\n",
              "          4.00109991e-05, -9.37879789e-05,  2.75882719e-04,\n",
              "         -9.89637348e-03,  8.88848787e-06,  3.53899941e-04,\n",
              "          1.71692390e-03,  4.84567168e-04, -2.07254582e-03,\n",
              "         -1.28154917e-02,  2.92458723e-04, -6.79069453e-03,\n",
              "         -3.98351314e-04, -2.32087431e-03,  3.99023529e-04,\n",
              "         -1.37083618e-03, -3.08115202e-03,  1.52269705e-03],\n",
              "        [-9.03930515e-04,  3.42430219e-04, -8.99796108e-03,\n",
              "         -1.22666445e-04,  0.00000000e+00, -1.12230233e-02,\n",
              "         -8.57710184e-03,  4.05186505e-04, -2.42817135e-03,\n",
              "         -1.03050644e-02,  0.00000000e+00, -9.47182688e-05,\n",
              "         -2.99852852e-03, -7.03601318e-03, -8.15696589e-03,\n",
              "          4.38346131e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.37385850e-05, -3.03353276e-03, -1.75072866e-04,\n",
              "         -2.07300782e-02, -4.36654568e-03,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.44593807e-03,  0.00000000e+00,\n",
              "         -1.50926673e-02,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00,  0.00000000e+00, -2.09051511e-02,\n",
              "         -2.15898267e-02,  6.84675627e-04, -2.15898267e-02,\n",
              "          6.84675627e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "         -5.14284317e-04,  0.00000000e+00, -3.08516981e-04,\n",
              "         -4.71800275e-03,  0.00000000e+00, -2.80664454e-03,\n",
              "          6.68541790e-04, -4.77885028e-03, -8.62681268e-03,\n",
              "          1.79418682e-04, -4.25417863e-03, -1.66509724e-02,\n",
              "         -7.06486906e-04, -1.50173035e-02, -3.31649964e-03,\n",
              "          0.00000000e+00, -1.86486107e-03,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.07300782e-02, -1.75072866e-04,\n",
              "          0.00000000e+00,  0.00000000e+00, -1.88652171e-02,\n",
              "         -2.03993394e-03,  0.00000000e+00,  0.00000000e+00,\n",
              "         -3.17020794e-04, -4.71263454e-03, -4.91534158e-04,\n",
              "          0.00000000e+00, -8.17030707e-03, -7.53011580e-03,\n",
              "          3.16461292e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "         -7.06486906e-04, -6.62427140e-03, -4.91534158e-04,\n",
              "          0.00000000e+00, -5.92431864e-03, -7.47500125e-03,\n",
              "          3.16461292e-04, -2.09051511e-02,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.12216124e-02,  3.16461292e-04,\n",
              "          0.00000000e+00, -2.11494571e-02,  2.44305988e-04,\n",
              "         -3.90025614e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -2.05151255e-02,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.55156648e-02, -6.46863224e-03,\n",
              "          0.00000000e+00,  1.92422931e-03, -1.64497361e-04,\n",
              "         -6.80585939e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "          2.92850476e-04, -2.57206511e-03, -1.69166432e-03,\n",
              "         -4.16848867e-03, -1.27657834e-02, -1.68891396e-02,\n",
              "         -1.15431291e-03,  9.99337382e-04, -9.48703693e-04,\n",
              "         -2.20584537e-03,  0.00000000e+00, -7.06486906e-04],\n",
              "        [-1.00108231e-02,  2.91776830e-04,  4.74617232e-02,\n",
              "          2.51515382e-02, -7.37943088e-04,  5.05429451e-02,\n",
              "          5.14258977e-03,  3.71707152e-04,  5.52712518e-02,\n",
              "          5.19136684e-02,  5.47250838e-03, -5.01753077e-04,\n",
              "          4.06922746e-02,  2.44647831e-02,  3.12607381e-02,\n",
              "          4.66217193e-03, -3.78269907e-04, -4.64119105e-04,\n",
              "          9.92725224e-04,  6.49815796e-03,  1.29202049e-01,\n",
              "         -1.65028318e-02, -1.00733916e-02,  1.39441048e-02,\n",
              "          1.03077889e-01, -1.14019061e-02,  1.21101252e-03,\n",
              "         -6.14262453e-02,  1.37318068e-02,  3.10314601e-02,\n",
              "          3.26044867e-02, -3.30190700e-03,  1.16001124e-01,\n",
              "          1.34656328e-01, -2.19571109e-02, -9.02656466e-03,\n",
              "          1.21725782e-01,  9.85106874e-02, -3.04928927e-03,\n",
              "          9.36831622e-03,  1.97194787e-02, -6.42232576e-03,\n",
              "         -1.09183321e-02, -1.50202723e-03,  1.99480723e-02,\n",
              "          1.04067479e-03, -3.32930395e-03, -1.02420806e-02,\n",
              "         -4.24653245e-04,  3.86310759e-02,  7.40681413e-02,\n",
              "          7.96389604e-02,  5.79735785e-02, -1.35290490e-02,\n",
              "         -6.78609884e-03, -4.59817392e-03,  9.43049343e-04,\n",
              "          9.50038284e-02,  1.69151389e-02, -1.62799567e-04,\n",
              "         -6.16958000e-04,  8.94405586e-02,  2.58948360e-02,\n",
              "         -2.01921951e-03,  1.30722328e-02,  1.21101252e-03,\n",
              "         -3.34092709e-03, -7.01502372e-03,  1.86623568e-02,\n",
              "         -3.79929283e-03,  6.17957879e-02,  3.18388775e-02,\n",
              "          2.74193272e-04,  1.48546538e-02,  1.21101252e-03,\n",
              "         -3.30033898e-03, -7.06414001e-03,  1.71340219e-02,\n",
              "         -3.79929283e-03,  5.40071274e-02,  3.86334941e-02,\n",
              "          1.02267917e-03,  1.12699217e-01, -2.22778963e-03,\n",
              "         -1.57150320e-03,  1.16224317e-01,  2.74193272e-04,\n",
              "          1.21101252e-03,  1.25444965e-01, -1.39567609e-02,\n",
              "          7.46779994e-02, -1.16550335e-03,  4.97105824e-02,\n",
              "          1.21101252e-03, -1.17348739e-02, -1.04116921e-03,\n",
              "          6.70376451e-02, -1.88906197e-02, -1.86869516e-02,\n",
              "         -7.71496495e-04,  2.93055766e-03, -9.78652181e-04,\n",
              "          8.40689128e-02, -9.69009093e-04, -9.67524338e-03,\n",
              "         -6.28202223e-03, -1.09021301e-02, -1.33709982e-03,\n",
              "          1.29423164e-01,  1.14725485e-02,  4.64854658e-02,\n",
              "         -6.82965647e-03,  2.97284725e-02, -5.89249393e-03,\n",
              "          4.31955325e-02,  1.25942905e-02, -6.58239368e-03],\n",
              "        [ 1.85375906e-03, -8.34369076e-05, -1.39834477e-02,\n",
              "         -6.02089283e-03,  8.27163462e-05, -1.09128790e-02,\n",
              "         -1.75581470e-03, -8.26630139e-05, -1.24195940e-02,\n",
              "         -1.48061093e-02, -5.89650359e-05,  9.11463360e-05,\n",
              "         -1.13707966e-02, -2.76257376e-03, -1.29170892e-02,\n",
              "         -2.17424364e-04,  0.00000000e+00,  0.00000000e+00,\n",
              "          4.63660402e-04, -2.29213876e-03, -3.31337368e-02,\n",
              "          4.06955583e-03,  2.07226447e-03, -8.84652485e-04,\n",
              "         -1.92658463e-02,  2.76354836e-03, -1.77679141e-04,\n",
              "          8.18470602e-03, -3.86178056e-03, -8.67683950e-03,\n",
              "         -9.21790186e-03,  3.53176818e-04, -2.94173578e-02,\n",
              "         -3.30340431e-02,  3.96986205e-03,  2.82352723e-03,\n",
              "         -3.18877082e-02, -2.71291318e-02,  9.16547214e-04,\n",
              "         -2.19096859e-03, -3.36215103e-03,  1.94345681e-04,\n",
              "          1.31981395e-03,  2.41439183e-04, -1.85162786e-03,\n",
              "         -3.93736123e-04,  3.92475849e-04,  2.75341043e-03,\n",
              "          4.54021040e-05, -5.98377495e-03, -2.30804061e-02,\n",
              "         -2.27009208e-02, -9.00866673e-03,  3.39190478e-03,\n",
              "         -1.78445888e-03,  1.03796062e-03,  7.87852742e-04,\n",
              "         -2.28606062e-02, -6.95975123e-03, -3.16762895e-05,\n",
              "          4.39140706e-04, -2.09146907e-02, -8.94017687e-03,\n",
              "          3.51545843e-04, -2.19553120e-03, -1.77679141e-04,\n",
              "          9.55990094e-04,  3.48798870e-04, -3.62081084e-03,\n",
              "          4.15856426e-04, -1.66910912e-02, -8.04927706e-03,\n",
              "         -5.04369205e-05, -2.78564827e-03, -1.77679141e-04,\n",
              "          1.04763231e-03,  3.75012561e-04, -2.90970016e-03,\n",
              "          4.15856426e-04, -1.54185401e-02, -9.32159901e-03,\n",
              "         -2.89515611e-04, -2.90641810e-02,  2.61725853e-04,\n",
              "          1.54130573e-04, -2.94296005e-02, -5.04369205e-05,\n",
              "         -1.77679141e-04, -3.25405310e-02,  3.65402919e-03,\n",
              "         -2.37582199e-02,  0.00000000e+00, -9.59755507e-03,\n",
              "         -1.77679141e-04,  4.46927306e-03,  1.12470574e-04,\n",
              "         -1.00314559e-02,  3.67322666e-03,  1.09285603e-03,\n",
              "          5.87502490e-05, -1.14955786e-03,  4.05079865e-05,\n",
              "         -2.30258839e-02,  1.64905085e-04,  1.48944561e-03,\n",
              "          1.70677029e-03,  2.93790797e-03,  2.12347568e-03,\n",
              "         -3.49875992e-02, -2.33418130e-03, -1.09766843e-02,\n",
              "         -7.45073910e-05, -9.20945969e-03,  9.43567568e-04,\n",
              "         -1.03642998e-02, -1.36897061e-03,  1.98617323e-03],\n",
              "        [-6.30559884e-03,  1.24381441e-04,  2.50218601e-02,\n",
              "          1.26513763e-02, -8.43536208e-04,  2.58825281e-02,\n",
              "         -8.32235772e-04,  2.57658103e-04,  3.22712604e-02,\n",
              "          2.48343282e-02,  2.95821259e-03, -4.05719013e-04,\n",
              "          2.23715185e-02,  1.00695148e-02,  1.40258665e-02,\n",
              "          2.16623809e-03, -2.45035454e-04, -2.67534610e-04,\n",
              "          1.01255636e-03,  4.84539323e-03,  7.58089690e-02,\n",
              "         -1.92779581e-02, -6.89749512e-03,  6.37591020e-03,\n",
              "          5.57908154e-02, -8.77829816e-03,  3.63742195e-05,\n",
              "         -4.15238188e-02,  9.08563564e-03,  1.85701690e-02,\n",
              "          2.38717186e-02, -2.25986564e-03,  5.87908766e-02,\n",
              "          6.86686283e-02, -1.21376173e-02, -1.42095854e-02,\n",
              "          7.07405963e-02,  5.82172014e-02, -1.44316272e-03,\n",
              "          4.59570328e-03,  1.21509593e-02, -3.51259731e-03,\n",
              "         -8.88417037e-03, -8.95745001e-04,  8.85841081e-03,\n",
              "          5.86952078e-04, -5.39555131e-03, -7.19904360e-03,\n",
              "         -5.47945592e-04,  2.10156637e-02,  3.55153472e-02,\n",
              "          4.92725690e-02,  2.38993875e-02, -1.02420738e-02,\n",
              "         -2.74496840e-03, -3.65390339e-03, -3.26556421e-04,\n",
              "          5.66293583e-02,  2.43691874e-04, -1.54828698e-05,\n",
              "          3.75725620e-04,  5.65394965e-02,  2.19247362e-03,\n",
              "         -2.57668480e-03,  8.30867869e-03,  3.63742195e-05,\n",
              "         -1.50097377e-03, -6.75298576e-03,  1.01920067e-02,\n",
              "         -2.25986564e-03,  3.38263247e-02,  1.43915024e-02,\n",
              "          2.89949392e-04,  9.04083775e-03,  3.63742195e-05,\n",
              "         -1.65766710e-03, -7.03308816e-03,  9.77014667e-03,\n",
              "         -2.25986564e-03,  2.60116326e-02,  2.17754657e-02,\n",
              "          8.47174810e-04,  5.65310109e-02, -1.28217494e-03,\n",
              "         -9.77690697e-04,  5.85009272e-02,  2.89949392e-04,\n",
              "          3.63742195e-05,  6.25434766e-02, -6.04883988e-03,\n",
              "          4.60344869e-02, -6.97918425e-04,  2.95334083e-02,\n",
              "          3.63742195e-05, -1.83753401e-02, -5.73471787e-04,\n",
              "          3.93175832e-02, -1.68419174e-02, -1.67379216e-02,\n",
              "         -5.47651851e-04,  1.84063314e-03, -9.18619204e-04,\n",
              "          5.15557274e-02, -5.63351006e-04, -4.39786987e-03,\n",
              "         -3.41216070e-03, -6.82188733e-03, -1.29140854e-03,\n",
              "          7.32136818e-02, -7.59344429e-04,  1.38895868e-02,\n",
              "         -2.00518160e-03,  1.89979336e-02, -4.68239175e-03,\n",
              "          2.56805759e-02,  7.70726101e-03, -3.05677303e-03]]),\n",
              " 'dW2': array([[-2.63444622e-05, -4.40912621e-02, -8.81071587e-03,\n",
              "         -9.04771698e-04,  1.59716702e-03, -4.61137017e-02,\n",
              "         -3.00556356e-02, -1.34486037e-02],\n",
              "        [-3.37982343e-07, -2.36611847e-02, -7.85475953e-03,\n",
              "         -1.58453525e-03,  3.14612405e-04, -2.20600172e-02,\n",
              "         -1.19624427e-02, -1.55849561e-02],\n",
              "        [ 3.19676690e-05,  1.20356091e-01,  3.56432175e-02,\n",
              "          5.31207025e-03, -4.28721343e-03,  9.42300697e-02,\n",
              "          6.13014517e-02,  6.92872338e-02],\n",
              "        [-1.18997742e-05, -2.91452054e-03,  4.92278647e-04,\n",
              "          8.46171055e-04,  1.03003769e-03,  2.86091647e-03,\n",
              "         -1.83045856e-03,  2.79078161e-03]]),\n",
              " 'dW3': array([[ 3.07478971e-03,  3.21425404e-02,  3.83575768e-02,\n",
              "         -1.16860419e-03],\n",
              "        [ 3.37658189e-04,  2.23956459e-03,  2.66605106e-03,\n",
              "         -7.39396728e-05],\n",
              "        [ 1.36419599e-02,  9.16047845e-02,  1.12447759e-01,\n",
              "         -3.14473713e-03]]),\n",
              " 'dW4': array([[-0.04200037, -0.11325024, -0.08186027]]),\n",
              " 'db1': array([[-4.84366123e-05],\n",
              "        [-2.81682096e-02],\n",
              "        [ 1.06079713e-01],\n",
              "        [-1.20401878e-02],\n",
              "        [-2.09051511e-02],\n",
              "        [ 1.12699217e-01],\n",
              "        [-2.90641810e-02],\n",
              "        [ 5.65310109e-02]]),\n",
              " 'db2': array([[-0.05207731],\n",
              "        [-0.03194398],\n",
              "        [ 0.15359576],\n",
              "        [-0.00079555]]),\n",
              " 'db3': array([[0.05147904],\n",
              "        [0.00365194],\n",
              "        [0.14952695]]),\n",
              " 'db4': array([[-0.18183409]])}"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UPDATE"
      ],
      "metadata": {
        "id": "AMPVr2e9aIyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: update_parameters\n",
        "\n",
        "def update_parameters(params, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "    \n",
        "    Arguments:\n",
        "    params -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "                  parameters[\"W\" + str(l)] = ... \n",
        "                  parameters[\"b\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    parameters = params.copy()\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Update rule for each parameter. Use a for loop.\n",
        "    #(≈ 2 lines of code)\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)]- (learning_rate * grads[\"dW\" + str(l+1)])\n",
        "        parameters[\"b\" + str(l+1)] =parameters[\"b\" + str(l+1)]-(learning_rate * grads[\"db\" + str(l+1)])\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "5cVxT_vhRaof"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "ILFwl6PXfIeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: L_layer_model\n",
        "\n",
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    print_cost -- if True, it prints the cost every 100 steps\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization.\n",
        "    #(≈ 1 line of code)\n",
        "    parameters = initialize_parameters_deep(layers_dims)\n",
        "    # YOUR CODE STARTS HERE\n",
        "    \n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
        "        #(≈ 1 line of code)\n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "        \n",
        "        # Compute cost.\n",
        "        #(≈ 1 line of code)\n",
        "        cost = cost_function(AL, Y)\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "    \n",
        "        # Backward propagation.\n",
        "        #(≈ 1 line of code)\n",
        "        grads = L_model_backward(AL, Y, caches)    \n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        " \n",
        "        # Update parameters.\n",
        "        #(≈ 1 line of code)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        # YOUR CODE STARTS HERE\n",
        "        \n",
        "        \n",
        "        # YOUR CODE ENDS HERE\n",
        "                \n",
        "        # Print the cost every 100 iterations\n",
        "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
        "        if i % 100 == 0 or i == num_iterations:\n",
        "            costs.append(cost)\n",
        "    \n",
        "    return parameters, costs"
      ],
      "metadata": {
        "id": "h9tQ-agmaNf8"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters, costs = L_layer_model(X_train.T, Y_train_reshaped, [117,8,4,3,1], learning_rate = 0.0075, num_iterations = 6000, print_cost=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj0URIrham9P",
        "outputId": "70a56837-4c3c-4c2a-c999-a466bbd91014"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 0.6743943096030101\n",
            "Cost after iteration 100: 0.5207215753833273\n",
            "Cost after iteration 200: 0.45484010707503647\n",
            "Cost after iteration 300: 0.40129964077413605\n",
            "Cost after iteration 400: 0.3541069763427029\n",
            "Cost after iteration 500: 0.3139106008880702\n",
            "Cost after iteration 600: 0.2804891622201992\n",
            "Cost after iteration 700: 0.25274389507005685\n",
            "Cost after iteration 800: 0.22969505849954955\n",
            "Cost after iteration 900: 0.2101619946001716\n",
            "Cost after iteration 1000: 0.1933192201478848\n",
            "Cost after iteration 1100: 0.17869786416700825\n",
            "Cost after iteration 1200: 0.16590588495662079\n",
            "Cost after iteration 1300: 0.15468011322124148\n",
            "Cost after iteration 1400: 0.14476703377394126\n",
            "Cost after iteration 1500: 0.13595283891604906\n",
            "Cost after iteration 1600: 0.1280541671427569\n",
            "Cost after iteration 1700: 0.12093462685232938\n",
            "Cost after iteration 1800: 0.11447778885587374\n",
            "Cost after iteration 1900: 0.10864165301984119\n",
            "Cost after iteration 2000: 0.10333977520592091\n",
            "Cost after iteration 2100: 0.09848982671193622\n",
            "Cost after iteration 2200: 0.09402467986866304\n",
            "Cost after iteration 2300: 0.08990140622776448\n",
            "Cost after iteration 2400: 0.08608580228567815\n",
            "Cost after iteration 2500: 0.08255175258739511\n",
            "Cost after iteration 2600: 0.07926437787439759\n",
            "Cost after iteration 2700: 0.07620229377240194\n",
            "Cost after iteration 2800: 0.07334119320908306\n",
            "Cost after iteration 2900: 0.0706580412353415\n",
            "Cost after iteration 3000: 0.06813358328606935\n",
            "Cost after iteration 3100: 0.06575900301516996\n",
            "Cost after iteration 3200: 0.06351753385843725\n",
            "Cost after iteration 3300: 0.061397425341912185\n",
            "Cost after iteration 3400: 0.05938986973018545\n",
            "Cost after iteration 3500: 0.057483996713987906\n",
            "Cost after iteration 3600: 0.055672325557025455\n",
            "Cost after iteration 3700: 0.05395033943083144\n",
            "Cost after iteration 3800: 0.052310174089190545\n",
            "Cost after iteration 3900: 0.05074572902698985\n",
            "Cost after iteration 4000: 0.049251999464031776\n",
            "Cost after iteration 4100: 0.04782536768593485\n",
            "Cost after iteration 4200: 0.04646300852979955\n",
            "Cost after iteration 4300: 0.045161689890118345\n",
            "Cost after iteration 4400: 0.04391671450959981\n",
            "Cost after iteration 4500: 0.04272603587420762\n",
            "Cost after iteration 4600: 0.04158644427911972\n",
            "Cost after iteration 4700: 0.04049564849282347\n",
            "Cost after iteration 4800: 0.03945200968576065\n",
            "Cost after iteration 4900: 0.038453080309617985\n",
            "Cost after iteration 5000: 0.037496463915051896\n",
            "Cost after iteration 5100: 0.03658005670307139\n",
            "Cost after iteration 5200: 0.0357019303193034\n",
            "Cost after iteration 5300: 0.03486033631681391\n",
            "Cost after iteration 5400: 0.03405402663306607\n",
            "Cost after iteration 5500: 0.0332811142423575\n",
            "Cost after iteration 5600: 0.03253951820704504\n",
            "Cost after iteration 5700: 0.03182845866268641\n",
            "Cost after iteration 5800: 0.03114628789886546\n",
            "Cost after iteration 5900: 0.030491898917650296\n",
            "Cost after iteration 5999: 0.02986968914193235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_dev.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ2V6RE5dedK",
        "outputId": "bc7783c8-98c0-42ba-f6b8-6c91e9cad937"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(812,)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "pGEoCMurfVBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(parameters, X):\n",
        "    \"\"\"\n",
        "    Using the learned parameters, predicts a class for each example in X\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    X -- input data of size (n_x, m)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
        "    #(≈ 2 lines of code)\n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    predictions = np.round(A2)\n",
        "    # YOUR CODE STARTS HERE\n",
        "    \n",
        "    \n",
        "    # YOUR CODE ENDS HERE\n",
        "    \n",
        "    return predictions"
      ],
      "metadata": {
        "id": "1JD0P_iSeBX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AL_hat, cache = L_model_forward(X_dev.T, parameters)\n",
        "Y_dev_reshaped = np.reshape(Y_dev,(1,812))\n",
        "cost_function(AL_hat,Y_dev_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhV1ShppcTKE",
        "outputId": "87f07369-c058-44d1-ddba-b5bc19b1a36d"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02855582980978054"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = float((np.dot(Y_dev_reshaped,AL_hat.T) + np.dot(1 - Y_dev_reshaped, 1 - AL_hat.T)) / float(Y_dev_reshaped.size)*100)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE_YVMjpdMk3",
        "outputId": "ef7d11df-17a8-4fa6-850f-ddaf14c676c5"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.23353663085206"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_train = predict(X_train, Y_train, parameters)"
      ],
      "metadata": {
        "id": "8mZYJU9Ta-O2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}